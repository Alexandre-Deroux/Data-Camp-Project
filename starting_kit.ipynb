{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Municipal farming area RAMP challenge\n",
    "\n",
    "AVAKIAN Alexia, DEROUX Alexandre, ERRAJI Kenza, GUILLAUME Constantin, MARIN-BERTIN Guillaume, TOZZA Jean\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The [dataset](https://www.data.gouv.fr/fr/datasets/historique-detaille-des-surfaces-cheptels-et-nombre-doperateurs-par-commune) originates from the agricultural agency [Agence Bio](https://www.agencebio.org) and aims to track farming activities across French municipalities from 2008 to 2023. It includes detailed information on the location of the farming parcels (region, department, etc.) and the usage of these parcels (surface, type of production, etc.).\n",
    "\n",
    "This data covers metropolitan France and the DROMs. This is anonymized data, i.e. the information concerning the natural or legal person who cultivates these plots is absent.\n",
    "\n",
    "The challenge is to design an algorithm able to predict the activity type (`code_activities`) based on the other characteristics of the farming parcels. \n",
    "\n",
    "During recent years, a push for a more sustainable agriculture and farming practices has been made, with significant implications regarding environmental and health concerns.\n",
    "\n",
    "Understanding farming activity patterns can help policy makers plan more appropriate initiatives in order to support farming organizations and farmers, encourage the transition to organic production, and improve the sustainability of practices. Previous policies can also be evaluated thanks to this.\n",
    "\n",
    "\n",
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import problem\n",
    "\n",
    "X_df, y = problem.get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Dataset Shape:\", X_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge evaluation\n",
    "\n",
    "In this challenge, the evaluation is based on prediction accuracy.\n",
    "\n",
    "The dataset is split into 80% for the training set and 20% for the test set. To ensure that the distribution of the target data is preserved in both sets, the `stratify` parameter is used during splitting.\n",
    "\n",
    "The best models will be those performing the highest accuracy on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The pipeline workflow\n",
    "\n",
    "The input data are stored in a dataframe. To go from a dataframe to a numpy array we will use a scikit-learn column transformer. The first example we will write will just consist in selecting a subset of columns we want to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %load submissions/starting_kit/estimator.py\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def get_estimator():\n",
    "    pipe = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n",
    "    )\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing using a scikit-learn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(get_estimator(), X_df, y, cv=5, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission\n",
    "\n",
    "To submit your code, you can refer to the [online documentation](https://paris-saclay-cds.github.io/ramp-docs/ramp-workflow/stable/using_kits.html)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
